<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>MCoT-4M â€“ EPFL AI Project</title>
  <link rel="stylesheet" href="style.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pdfobject/2.2.12/pdfobject.min.js"></script>
</head>
<body>
  <!-- Navigation Bar -->
  <nav>
    <div class="nav-container">
      <div class="nav-content">
        <a href="#" class="nav-brand">MCoT-4M</a>
        <div class="nav-links">
          <a href="#abstract">Abstract</a>
          <a href="#architecture">Architecture</a>
          <a href="#mcot-steps">MCoT Steps</a>
          <a href="#results">Results</a>
          <a href="#paper">Paper</a>
        </div>
      </div>
    </div>
  </nav>

  <!-- Header -->
  <header>
    <h1>MCoT-4M</h1>
    <p>Multimodal Chain of Thought for 4M Vision-Language Models</p>
  </header>

  <!-- Preamble Section -->
  <section>
    <h2>Our Journey</h2>
    <div class="journey-box">
      <p>
        The development of MCoT-4M represents a significant advancement in multimodal AI research, building upon several key milestones:
      </p>
      <ol class="journey-list">
        <li>
          <span class="title">Initial Challenge:</span>
          <p class="description">Traditional vision-language models struggled with complex reasoning tasks, particularly in visual question answering (VQA).</p>
        </li>
        <li>
          <span class="title">EPFL 4M Foundation:</span>
          <p class="description">We started with the powerful EPFL 4M model, which provided a robust base for multimodal understanding.</p>
        </li>
        <li>
          <span class="title">MINT Integration:</span>
          <p class="description">By incorporating MINT's Multimodal Chain of Thought architecture, we introduced structured reasoning capabilities.</p>
        </li>
        <li>
          <span class="title">Key Innovation:</span>
          <p class="description">Our breakthrough was integrating planning and acting stages directly into the 4M pipeline, eliminating the need for external LLMs.</p>
        </li>
        <li>
          <span class="title">Final Achievement:</span>
          <p class="description">The resulting MCoT-4M model demonstrates enhanced reasoning capabilities while maintaining efficiency and scalability.</p>
        </li>
      </ol>
    </div>
  </section>

  <!-- Abstract Section -->
  <section id="abstract">
    <h2>Abstract</h2>
    <p>
      We extend the EPFL 4M model with MINT's Multimodal Chain of Thought (MCoT) architecture by integrating planning and acting stages directly into the 4M pipeline without external LLMs. This approach enhances reasoning in VQA tasks.
    </p>
  </section>

  <!-- Architecture Section -->
  <section id="architecture">
    <h2>Architecture</h2>
    <img src="assets/mcot-diagram.png" alt="MCoT Architecture Diagram" class="architecture-image">
    <p>
      The MCoTWrapper module prepends stage-specific embeddings to the input, orchestrating the Planning â†’ Acting sequence in a self-contained fashion using 4M-21XL checkpoints.
    </p>
  </section>

  <!-- MCoT Steps Table -->
  <section id="mcot-steps">
    <h2>MCoT Process Steps</h2>
    <div class="table-container">
      <table>
        <thead>
          <tr>
            <th>Input</th>
            <th>Planning</th>
            <th>Acting</th>
            <th>Reflection</th>
            <th>Correction</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>
              <p>Visual and textual input from the environment</p>
            </td>
            <td>
              <p>Generate step-by-step reasoning plan</p>
              <p>Break down complex tasks into manageable steps</p>
            </td>
            <td>
              <p>Execute planned actions</p>
              <p>Apply reasoning to solve the task</p>
            </td>
            <td>
              <p>Evaluate results</p>
              <p>Analyze success of actions</p>
            </td>
            <td>
              <p>Adjust approach if needed</p>
              <p>Refine solution based on reflection</p>
            </td>
          </tr>
        </tbody>
      </table>
    </div>
  </section>

  <!-- Results Section -->
  <section id="results">
    <h2>Results</h2>
    <ul class="journey-list">
      <li>Training loss: 0.7</li>
      <li>Eval loss: 1.2</li>
      <li>Qualitative: More coherent VQA answers for complex reasoning</li>
    </ul>
  </section>

  <!-- PDF Viewer Section -->
  <section id="paper">
    <h2>Paper Preview</h2>
    <div id="pdf-viewer" class="pdf-container"></div>
  </section>

  <!-- Paper + GitHub -->
  <section class="links-section">
    <a href="assets/update.pdf">ðŸ“„ Read the Paper</a> |
    <a href="https://github.com/charlesmercier/mcot4M-website">ðŸ’» View on GitHub</a>
  </section>

  <!-- Footer -->
  <footer>
    Â© 2025 EPFL â€“ MCoT-4M Project
  </footer>

  <script>
    // Initialize PDF viewer
    PDFObject.embed("assets/update.pdf", "#pdf-viewer");
  </script>
</body>
</html>
